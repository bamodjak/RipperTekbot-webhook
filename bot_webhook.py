import logging
import os
import random
import string
import asyncio
import warnings
import io
import re
import httpx
from typing import List, Dict, Set

# Import get_english_words_set from the first code's dependencies
try:
    from english_words import get_english_words_set
    # Load English words
    ENGLISH_WORDS = get_english_words_set(['web2'], lower=True)
except ImportError:
    logging.warning("english_words library not found. English word generation will be limited or not function as expected.")
    ENGLISH_WORDS = set() # Fallback empty set if library not present

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
from telegram.error import BadRequest, TimedOut, RetryAfter
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ConversationHandler,
    ContextTypes,
    filters
)

# Suppress the PTBUserWarning
warnings.filterwarnings(
    "ignore",
    message="If 'per_message=False', 'CallbackQueryHandler' will not be tracked for every message.",
    category=UserWarning,
    module="telegram.ext.conversationhandler"
)

# Setup logging
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# Load Telegram token
TOKEN = os.getenv("TELEGRAM_TOKEN")
if not TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN environment variable not set!")

# --- States for ConversationHandler (Merged from both codes) ---
INITIAL_MENU, \
ASK_USERNAME_COUNT, ASK_PATTERN, ASK_DELAY, BULK_LIST, \
HOW_TO_INFO, SET_LANGUAGE, \
ASK_WORD_LENGTH, ASK_WORD_FORMULA, ASK_WORD_COUNT, SHOW_WORD_RESULTS = range(11)


# --- Data for Word Generation ---
# Arabic words dataset (ensuring correct UTF-8 representation)
ARABIC_WORDS = {
    'ÙƒØªØ§Ø¨', 'Ù…Ø¯Ø±Ø³Ø©', 'Ø¨ÙŠØª', 'Ù‚Ù„Ù…', 'ÙˆØ±Ù‚Ø©', 'Ø·Ø§Ù„Ø¨', 'Ù…Ø¹Ù„Ù…', 'Ø¯Ø±Ø³', 'Ø§Ù…ØªØ­Ø§Ù†', 'Ù†Ø¬Ø§Ø­',
    'Ø­Ø¨', 'Ø³Ù„Ø§Ù…', 'Ø£Ù…Ù„', 'Ù†ÙˆØ±', 'Ø­ÙŠØ§Ø©', 'Ø¹Ù…Ù„', 'ÙˆÙ‚Øª', 'ÙŠÙˆÙ…', 'Ù„ÙŠÙ„Ø©', 'ØµØ¨Ø§Ø­',
    'Ù…Ø³Ø§Ø¡', 'Ø´Ù…Ø³', 'Ù‚Ù…Ø±', 'Ù†Ø¬Ù…', 'Ø¨Ø­Ø±', 'Ø¬Ø¨Ù„', 'Ø´Ø¬Ø±Ø©', 'Ø²Ù‡Ø±Ø©', 'Ø·Ø§Ø¦Ø±', 'Ø³Ù…Ùƒ',
    'Ø·Ø¹Ø§Ù…', 'Ù…Ø§Ø¡', 'Ø®Ø¨Ø²', 'Ù„Ø­Ù…', 'ÙØ§ÙƒÙ‡Ø©', 'Ø®Ø¶Ø§Ø±', 'Ù„Ø¨Ù†', 'Ø´Ø§ÙŠ', 'Ù‚Ù‡ÙˆØ©', 'Ø¹ØµÙŠØ±',
    'Ø£Ø¨', 'Ø£Ù…', 'Ø§Ø¨Ù†', 'Ø§Ø¨Ù†Ø©', 'Ø£Ø®', 'Ø£Ø®Øª', 'Ø¬Ø¯', 'Ø¬Ø¯Ø©', 'Ø¹Ù…', 'Ø®Ø§Ù„',
    'ØµØ¯ÙŠÙ‚', 'Ø¬Ø§Ø±', 'Ø¶ÙŠÙ', 'Ø·Ø¨ÙŠØ¨', 'Ù…Ù‡Ù†Ø¯Ø³', 'Ù…Ø¹Ù„Ù…', 'Ø·Ø§Ù„Ø¨', 'Ø¹Ø§Ù…Ù„', 'ØªØ§Ø¬Ø±', 'ÙÙ„Ø§Ø­',
    'Ø³ÙŠØ§Ø±Ø©', 'Ø­Ø§ÙÙ„Ø©', 'Ù‚Ø·Ø§Ø±', 'Ø·Ø§Ø¦Ø±Ø©', 'Ø¨Ø§Ø¨', 'Ù†Ø§ÙØ°Ø©', 'Ù…ÙØªØ§Ø­', 'ÙƒØ±Ø³ÙŠ', 'Ø·Ø§ÙˆÙ„Ø©', 'Ø³Ø±ÙŠØ±',
    'Ù„Ø¹Ø¨Ø©', 'ÙƒØ±Ø©', 'ÙÙŠÙ„Ù…', 'ÙƒØªØ§Ø¨', 'Ù…Ø¬Ù„Ø©', 'Ø¬Ø±ÙŠØ¯Ø©', 'ØªÙ„ÙØ§Ø²', 'Ø±Ø§Ø¯ÙŠÙˆ', 'Ù‡Ø§ØªÙ', 'Ø­Ø§Ø³ÙˆØ¨',
    'Ù…Ø§Ù„', 'Ø°Ù‡Ø¨', 'ÙØ¶Ø©', 'Ø­Ø¯ÙŠØ¯', 'Ø®Ø´Ø¨', 'Ø²Ø¬Ø§Ø¬', 'Ø¨Ù„Ø§Ø³ØªÙŠÙƒ', 'Ø­Ø¬Ø±', 'Ø±Ù…Ù„', 'ØªØ±Ø§Ø¨',
    'Ù†Ø§Ø±', 'Ù‡ÙˆØ§Ø¡', 'Ø±ÙŠØ­', 'Ù…Ø·Ø±', 'Ø«Ù„Ø¬', 'Ø³Ø­Ø§Ø¨', 'Ø±Ø¹Ø¯', 'Ø¨Ø±Ù‚', 'Ù‚ÙˆØ³', 'Ù„ÙˆÙ†',
    'Ø£Ø­Ù…Ø±', 'Ø£Ø²Ø±Ù‚', 'Ø£Ø®Ø¶Ø±', 'Ø£ØµÙØ±', 'Ø£Ø³ÙˆØ¯', 'Ø£Ø¨ÙŠØ¶', 'Ø¨Ù†ÙŠ', 'Ø±Ù…Ø§Ø¯ÙŠ', 'Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠ', 'Ø¨Ù†ÙØ³Ø¬ÙŠ',
    'ÙƒØ¨ÙŠØ±', 'ØµØºÙŠØ±', 'Ø·ÙˆÙŠÙ„', 'Ù‚ØµÙŠØ±', 'Ø¹Ø±ÙŠØ¶', 'Ø¶ÙŠÙ‚', 'Ø³Ù…ÙŠÙƒ', 'Ø±Ù‚ÙŠÙ‚', 'Ù‚ÙˆÙŠ', 'Ø¶Ø¹ÙŠÙ',
    'Ø³Ø±ÙŠØ¹', 'Ø¨Ø·ÙŠØ¡', 'Ø¬Ø¯ÙŠØ¯', 'Ù‚Ø¯ÙŠÙ…', 'Ø­Ø§Ø±', 'Ø¨Ø§Ø±Ø¯', 'Ø¬Ø§Ù', 'Ø±Ø·Ø¨', 'Ù†Ø¸ÙŠÙ', 'Ù‚Ø°Ø±',
    'Ø¬Ù…ÙŠÙ„', 'Ù‚Ø¨ÙŠØ­', 'Ø³Ù‡Ù„', 'ØµØ¹Ø¨', 'ØºÙ†ÙŠ', 'ÙÙ‚ÙŠØ±', 'Ø³Ø¹ÙŠØ¯', 'Ø­Ø²ÙŠÙ†', 'Ù‡Ø§Ø¯Ø¦', 'ØµØ§Ø®Ø¨',
    'Ù…Ø¯ÙŠÙ†Ø©', 'Ù‚Ø±ÙŠØ©', 'Ø´Ø§Ø±Ø¹', 'Ø¨Ù†Ø§ÙŠØ©', 'Ø¯ÙƒØ§Ù†', 'Ø³ÙˆÙ‚', 'Ù…Ø³Ø¬Ø¯', 'ÙƒÙ†ÙŠØ³Ø©', 'Ù…Ø³ØªØ´ÙÙ‰', 'Ø¬Ø§Ù…Ø¹Ø©',
    'Ø­Ø¯ÙŠÙ‚Ø©', 'Ø­Ù‚Ù„', 'ØºØ§Ø¨Ø©', 'ØµØ­Ø±Ø§Ø¡', 'ÙˆØ§Ø¯ÙŠ', 'Ù‡Ø¶Ø¨Ø©', 'Ø¬Ø²ÙŠØ±Ø©', 'Ø´Ø§Ø·Ø¦', 'Ù…ÙŠÙ†Ø§Ø¡', 'Ù‚Ù†Ø§Ø©',
    'Ø±Ù‚Ù…', 'Ø­Ø±Ù', 'ÙƒÙ„Ù…Ø©', 'Ø¬Ù…Ù„Ø©', 'ØµÙØ­Ø©', 'ÙØµÙ„', 'Ù‚ØµØ©', 'Ø´Ø¹Ø±', 'Ø£ØºÙ†ÙŠØ©', 'Ø±Ù‚Øµ',
    'Ù„Ø­Ù†', 'Ø¢Ù„Ø©', 'Ù…ÙˆØ³ÙŠÙ‚Ù‰', 'Ø±Ø³Ù…', 'ØµÙˆØ±Ø©', 'ÙÙ†', 'Ø«Ù‚Ø§ÙØ©', 'ØªØ§Ø±ÙŠØ®', 'Ø¬ØºØ±Ø§ÙÙŠØ§', 'Ø¹Ù„Ù…',
    'Ø­Ù‚', 'Ø¹Ø¯Ù„', 'Ù‚Ø§Ù†ÙˆÙ†', 'Ø­ÙƒÙ…', 'Ø¯ÙˆÙ„Ø©', 'Ø­ÙƒÙˆÙ…Ø©', 'Ø±Ø¦ÙŠØ³', 'ÙˆØ²ÙŠØ±', 'Ù…ÙˆØ¸Ù', 'Ù…ÙƒØªØ¨',
    'Ù…Ø´Ø±ÙˆØ¹', 'Ø®Ø·Ø©', 'Ù‡Ø¯Ù', 'Ù†ØªÙŠØ¬Ø©', 'Ø³Ø¨Ø¨', 'Ø·Ø±ÙŠÙ‚Ø©', 'ÙˆØ³ÙŠÙ„Ø©', 'Ø£Ø¯Ø§Ø©', 'Ø¢Ù„Ø©', 'Ø¬Ù‡Ø§Ø²',
    'Ø±Ø³Ø§Ù„Ø©', 'Ø¨Ø±ÙŠØ¯', 'Ø¹Ù†ÙˆØ§Ù†', 'Ø§Ø³Ù…', 'Ù„Ù‚Ø¨', 'Ø¹Ø§Ø¦Ù„Ø©', 'Ù‚ÙˆÙ…', 'Ø´Ø¹Ø¨', 'Ø£Ù…Ø©', 'ÙˆØ·Ù†',
    'Ø­Ø±Ø¨', 'Ø³Ù„Ù…', 'ØµÙ„Ø­', 'Ø§ØªÙØ§Ù‚', 'Ù…Ø¹Ø§Ù‡Ø¯Ø©', 'Ù‚Ø±Ø§Ø±', 'Ø§Ø®ØªÙŠØ§Ø±', 'Ø§Ù†ØªØ®Ø§Ø¨', 'ØªØµÙˆÙŠØª', 'Ø±Ø£ÙŠ',
    'ÙÙƒØ±', 'Ø¹Ù‚Ù„', 'Ø°Ù‡Ù†', 'Ø°ÙƒØ±', 'Ø°Ø§ÙƒØ±Ø©', 'Ø®ÙŠØ§Ù„', 'Ø­Ù„Ù…', 'Ø£Ù…Ù†ÙŠØ©', 'Ø±ØºØ¨Ø©', 'Ø­Ø§Ø¬Ø©',
    'Ø®ÙˆÙ', 'Ø´Ø¬Ø§Ø¹Ø©', 'Ø­Ù…Ø§Ø³', 'Ø­Ù…Ø§ÙŠØ©', 'Ø£Ù…Ø§Ù†', 'Ø®Ø·Ø±', 'Ù…Ø®Ø§Ø·Ø±Ø©', 'Ù…Ø­Ø§ÙˆÙ„Ø©', 'Ø¬Ù‡Ø¯', 'Ø¹Ù…Ù„',
    'Ø±Ø§Ø­Ø©', 'ØªØ¹Ø¨', 'Ù†ÙˆÙ…', 'ÙŠÙ‚Ø¸Ø©', 'Ø§Ø³ØªÙŠÙ‚Ø§Ø¸', 'Ø­Ø±ÙƒØ©', 'Ø³ÙƒÙˆÙ†', 'ÙˆÙ‚ÙˆÙ', 'Ø¬Ù„ÙˆØ³', 'Ù…Ø´ÙŠ',
    'Ø¬Ø±ÙŠ', 'Ù‚ÙØ²', 'Ø³Ø¨Ø§Ø­Ø©', 'Ø·ÙŠØ±Ø§Ù†', 'Ø³ÙØ±', 'Ø±Ø­Ù„Ø©', 'Ø²ÙŠØ§Ø±Ø©', 'Ù„Ù‚Ø§Ø¡', 'Ø§Ø¬ØªÙ…Ø§Ø¹', 'Ø­ÙÙ„Ø©',
    'Ø­Ù‚ÙŠÙ‚Ø©', 'ÙƒØ°Ø¨', 'ØµØ¯Ù‚', 'Ø£Ù…Ø§Ù†Ø©', 'Ø®ÙŠØ§Ù†Ø©', 'ÙˆÙØ§Ø¡', 'ØºØ¯Ø±', 'Ù…Ø³Ø§Ø¹Ø¯Ø©', 'Ø®Ø¯Ù…Ø©', 'Ù…Ø¹Ø±ÙˆÙ',
    'Ø´ÙƒØ±', 'Ø§Ù…ØªÙ†Ø§Ù†', 'ØªÙ‚Ø¯ÙŠØ±', 'Ø§Ø­ØªØ±Ø§Ù…', 'ØªÙƒØ±ÙŠÙ…', 'ØªÙ‡Ù†Ø¦Ø©', 'Ù…Ø¨Ø§Ø±ÙƒØ©', 'Ø¯Ø¹Ø§Ø¡', 'ØµÙ„Ø§Ø©', 'Ø¹Ø¨Ø§Ø¯Ø©',
    'Ø¥ÙŠÙ…Ø§Ù†', 'Ø¯ÙŠÙ†', 'Ø¹Ù‚ÙŠØ¯Ø©', 'Ù‚ÙŠÙ…Ø©', 'Ø£Ø®Ù„Ø§Ù‚', 'Ø³Ù„ÙˆÙƒ', 'Ø·Ø¨Ø¹', 'Ø®Ù„Ù‚', 'ØµÙØ©', 'Ù…ÙŠØ²Ø©',
    'Ø®Ø§ØµÙŠØ©', 'ØµÙØ©', 'Ø·Ø¨ÙŠØ¹Ø©', 'Ø·Ø¨Ø¹', 'Ø¹Ø§Ø¯Ø©', 'ØªÙ‚Ù„ÙŠØ¯', 'Ø¹Ø±Ù', 'Ù‚Ø§Ø¹Ø¯Ø©', 'Ù…Ø¨Ø¯Ø£', 'Ø£Ø³Ø§Ø³',
    'Ù…Ø³Ø£Ù„Ø©', 'Ù…ÙˆØ¶ÙˆØ¹', 'Ù‚Ø¶ÙŠØ©', 'Ù…Ø´ÙƒÙ„Ø©', 'Ø­Ù„', 'Ø¬ÙˆØ§Ø¨', 'Ø³Ø¤Ø§Ù„', 'Ø§Ø³ØªÙØ³Ø§Ø±', 'Ø·Ù„Ø¨', 'Ø±Ø¬Ø§Ø¡',
    'Ø£Ù…Ø±', 'Ù†Ù‡ÙŠ', 'Ø¥Ø°Ù†', 'Ù…Ù†Ø¹', 'Ø³Ù…Ø§Ø­', 'Ù…ÙˆØ§ÙÙ‚Ø©', 'Ø±ÙØ¶', 'Ø§Ø¹ØªØ±Ø§Ø¶', 'Ø§Ø­ØªØ¬Ø§Ø¬', 'Ø´ÙƒÙˆÙ‰',
    'ØªØ¸Ù„Ù…', 'Ø·Ø¹Ù†', 'Ø§Ø³ØªØ¦Ù†Ø§Ù', 'Ø­ÙƒÙ…', 'Ù‚Ø¶Ø§Ø¡', 'Ù…Ø­ÙƒÙ…Ø©', 'Ù‚Ø§Ø¶ÙŠ', 'Ù…Ø­Ø§Ù…', 'Ø´Ø§Ù‡Ø¯', 'Ø¯Ù„ÙŠÙ„',
    'Ø¨Ø±Ù‡Ø§Ù†', 'Ø¥Ø«Ø¨Ø§Øª', 'Ù†ÙÙŠ', 'Ø¥Ù‚Ø±Ø§Ø±', 'Ø§Ø¹ØªØ±Ø§Ù', 'Ø¥Ù†ÙƒØ§Ø±', 'ØªØµØ¯ÙŠÙ‚', 'ØªÙƒØ°ÙŠØ¨', 'ØªØ£ÙƒÙŠØ¯', 'Ù†ÙÙŠ',
    'Ù…ÙˆØ§ÙÙ‚Ø©', 'Ø±Ø¶Ø§', 'Ù‚Ø¨ÙˆÙ„', 'Ø§Ø³ØªØ­Ø³Ø§Ù†', 'Ø¥Ø¹Ø¬Ø§Ø¨', 'Ø­Ø¨', 'Ø¹Ø´Ù‚', 'Ù‡ÙˆÙ‰', 'Ø´ÙˆÙ‚', 'Ø­Ù†ÙŠÙ†',
    'ÙØ±Ø§Ù‚', 'ÙˆØ¯Ø§Ø¹', 'Ù„Ù‚Ø§Ø¡', 'Ø§Ø¬ØªÙ…Ø§Ø¹', 'Ø¬Ù…Ø¹', 'ØªØ¬Ù…Ø¹', 'Ø­Ø´Ø¯', 'ØªØ¸Ø§Ù‡Ø±', 'Ø§Ø­ØªÙØ§Ù„', 'Ø¹ÙŠØ¯',
    'Ù…Ù†Ø§Ø³Ø¨Ø©', 'Ø­Ø¯Ø«', 'ÙˆØ§Ù‚Ø¹Ø©', 'Ø­Ø§Ø¯Ø«Ø©', 'Ø£Ù…Ø±', 'Ø®Ø¨Ø±', 'Ù…Ø¹Ù„ÙˆÙ…Ø©', 'Ø¨ÙŠØ§Ù†', 'Ø¥Ø¹Ù„Ø§Ù†', 'Ù†Ø´Ø±',
    'Ø¥Ø°Ø§Ø¹Ø©', 'ØªÙ„ÙØ§Ø²', 'ØµØ­Ø§ÙØ©', 'Ø¥Ø¹Ù„Ø§Ù…', 'ÙˆØ³Ø§Ø¦Ù„', 'Ø§ØªØµØ§Ù„', 'ØªÙˆØ§ØµÙ„', 'Ø­Ø¯ÙŠØ«', 'ÙƒÙ„Ø§Ù…', 'Ù†Ù‚Ø§Ø´',
    'Ø¬Ø¯Ø§Ù„', 'Ù…Ù†Ø§Ù‚Ø´Ø©', 'Ø­ÙˆØ§Ø±', 'Ù…ÙØ§ÙˆØ¶Ø©', 'ØªÙØ§ÙˆØ¶', 'Ø§ØªÙØ§Ù‚', 'Ø¹Ù‚Ø¯', 'ØµÙÙ‚Ø©', 'ØªØ¬Ø§Ø±Ø©', 'Ø¨ÙŠØ¹',
    'Ø´Ø±Ø§Ø¡', 'ØªØ³ÙˆÙ‚', 'Ø³ÙˆÙ‚', 'Ø¯ÙƒØ§Ù†', 'Ù…Ø­Ù„', 'Ù…ØªØ¬Ø±', 'Ù…Ø®Ø²Ù†', 'Ù…Ø³ØªÙˆØ¯Ø¹', 'Ù…ØµÙ†Ø¹', 'Ø´Ø±ÙƒØ©',
    'Ù…Ø¤Ø³Ø³Ø©', 'Ù…Ù†Ø¸Ù…Ø©', 'Ø¬Ù…Ø¹ÙŠØ©', 'Ù†Ø§Ø¯ÙŠ', 'Ù…Ø±ÙƒØ²', 'Ù…Ø¹Ù‡Ø¯', 'Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©', 'Ø¬Ø§Ù…Ø¹Ø©', 'ÙƒÙ„ÙŠØ©', 'Ù…Ø¯Ø±Ø³Ø©',
    'ÙØµÙ„', 'Ù‚Ø³Ù…', 'Ø´Ø¹Ø¨Ø©', 'ÙˆØ­Ø¯Ø©', 'Ù…Ø¬Ù…ÙˆØ¹Ø©', 'ÙØ±ÙŠÙ‚', 'Ø·Ø§Ù‚Ù…', 'Ø¹Ø¶Ùˆ', 'Ø±Ø¦ÙŠØ³', 'Ù…Ø¯ÙŠØ±',
    'Ù…ÙˆØ¸Ù', 'Ø¹Ø§Ù…Ù„', 'Ø®Ø§Ø¯Ù…', 'Ø£Ø¬ÙŠØ±', 'Ù…Ø³ØªØ®Ø¯Ù…', 'ØµØ§Ø­Ø¨', 'Ù…Ø§Ù„Ùƒ', 'Ø±Ø¨', 'Ø³ÙŠØ¯', 'Ù‚Ø§Ø¦Ø¯',
    'Ø²Ø¹ÙŠÙ…', 'Ø±Ø¦ÙŠØ³', 'Ø­Ø§ÙƒÙ…', 'Ù…Ù„Ùƒ', 'Ø£Ù…ÙŠØ±', 'Ø³Ù„Ø·Ø§Ù†', 'Ø®Ù„ÙŠÙØ©', 'Ø¥Ù…Ø§Ù…', 'Ø´ÙŠØ®', 'Ø£Ø³ØªØ§Ø°',
    'Ø¯ÙƒØªÙˆØ±', 'Ù…Ù‡Ù†Ø¯Ø³', 'Ù…Ø­Ø§Ù…', 'Ø·Ø¨ÙŠØ¨', 'ØµÙŠØ¯Ù„ÙŠ', 'Ù…Ù…Ø±Ø¶', 'Ù…Ø±ÙŠØ¶', 'Ø¹Ù„Ø§Ø¬', 'Ø¯ÙˆØ§Ø¡', 'Ø´ÙØ§Ø¡',
    'Ù…Ø±Ø¶', 'Ø£Ù„Ù…', 'ÙˆØ¬Ø¹', 'ØµØ¯Ø§Ø¹', 'Ø­Ù…Ù‰', 'Ø¨Ø±Ø¯', 'Ø³Ø¹Ø§Ù„', 'Ø¹Ø·Ø³', 'ØªØ¹Ø¨', 'Ø¥Ø±Ù‡Ø§Ù‚',
    'Ø±Ø§Ø­Ø©', 'Ø§Ø³ØªØ±Ø®Ø§Ø¡', 'Ù†ÙˆÙ…', 'Ø­Ù„Ù…', 'ÙƒØ§Ø¨ÙˆØ³', 'ÙŠÙ‚Ø¸Ø©', 'Ø§Ù†ØªØ¨Ø§Ù‡', 'ØªØ±ÙƒÙŠØ²', 'Ø§Ù‡ØªÙ…Ø§Ù…', 'Ø¹Ù†Ø§ÙŠØ©',
    'Ø±Ø¹Ø§ÙŠØ©', 'Ø­Ù…Ø§ÙŠØ©', 'Ø¯ÙØ§Ø¹', 'Ù…Ù‚Ø§ÙˆÙ…Ø©', 'ØµÙ…ÙˆØ¯', 'ØªØ­Ù…Ù„', 'ØµØ¨Ø±', 'Ø§Ù†ØªØ¸Ø§Ø±', 'ØªØ±Ù‚Ø¨', 'Ø£Ù…Ù„',
    'Ø±Ø¬Ø§Ø¡', 'Ø¯Ø¹Ø§Ø¡', 'ØªÙ…Ù†ÙŠ', 'Ø­Ù„Ù…', 'Ø·Ù…ÙˆØ­', 'Ù‡Ø¯Ù', 'ØºØ§ÙŠØ©', 'Ù…Ù‚ØµØ¯', 'Ù‡Ø¯Ù', 'Ù…Ø±Ù…Ù‰',
    'Ù†ØªÙŠØ¬Ø©', 'Ø«Ù…Ø±Ø©', 'Ø¹Ø§Ù‚Ø¨Ø©', 'Ø¬Ø²Ø§Ø¡', 'Ù…ÙƒØ§ÙØ£Ø©', 'Ø¹Ù‚Ø§Ø¨', 'Ø¹Ù‚ÙˆØ¨Ø©', 'Ø¬Ø²Ø§Ø¡', 'Ù…ØµÙŠØ±', 'Ù‚Ø¯Ø±',
    'Ø­Ø¸', 'Ù†ØµÙŠØ¨', 'Ø­ØµØ©', 'Ù‚Ø³Ù…', 'Ø¬Ø²Ø¡', 'Ø¨Ø¹Ø¶', 'ÙƒÙ„', 'Ø¬Ù…ÙŠØ¹', 'Ø¹Ø§Ù…Ø©', 'Ø®Ø§ØµØ©',
    'Ù…Ø´ØªØ±ÙƒØ©', 'Ù…Ù†ÙØ±Ø¯Ø©', 'ÙˆØ­ÙŠØ¯Ø©', 'ÙØ±Ø¯ÙŠØ©', 'Ø¬Ù…Ø§Ø¹ÙŠØ©', 'Ø¹Ù…ÙˆÙ…ÙŠØ©', 'Ø®ØµÙˆØµÙŠØ©', 'Ø³Ø±ÙŠØ©', 'Ø¹Ù„Ù†ÙŠØ©', 'ÙˆØ§Ø¶Ø­Ø©',
    'Ø¸Ø§Ù‡Ø±Ø©', 'Ø®ÙÙŠØ©', 'Ø¨Ø§Ø·Ù†Ø©', 'Ø¯Ø§Ø®Ù„ÙŠØ©', 'Ø®Ø§Ø±Ø¬ÙŠØ©', 'Ø³Ø·Ø­ÙŠØ©', 'Ø¹Ù…ÙŠÙ‚Ø©', 'Ø¨Ø¹ÙŠØ¯Ø©', 'Ù‚Ø±ÙŠØ¨Ø©', 'Ù…ØªÙˆØ³Ø·Ø©'
}


# --- Constants for thresholds ---
UPDATE_INTERVAL_SECONDS = 1
UPDATE_INTERVAL_COUNT = 1
MIN_USERNAME_LENGTH = 5
MAX_USERNAME_LENGTH = 32
PLACEHOLDER_CHAR = 'x' # This is specific to username pattern generation

# Fallback words for Username generation
FALLBACK_WORDS_EN = [
    "user", "admin", "tech", "pro", "game", "bot", "tool", "alpha", "beta",
    "master", "geek", "coder", "dev", "creator", "digital", "online", "system",
    "prime", "expert", "fusion", "galaxy", "infinity", "legend", "nova", "omega",
    "phantom", "quest", "rocket", "spirit", "ultra", "vision", "wizard", "zenith",
    "swift", "spark", "glitch", "echo", "cipher", "matrix", "nexus", "orbit",
    "pulse", "quantum", "reboot", "stellar", "titan", "vortex", "zephyr", "byte",
    "liar", "love", "lion", "light", "lucky", "logic", "lunar", "limit", "level",
    "lab", "link", "leaf", "lark", "lava", "lazy", "leap", "lens", "loop", "lore",
    "blog", "chat", "club", "data", "deep", "dome", "epic", "fire", "flow", "force",
    "geek", "gold", "grid", "hero", "hive", "icon", "idea", "jolt", "jump", "king",
    "kraft", "laser", "link", "loom", "magic", "mega", "meta", "mind", "mirage", "myth",
    "nebula", "net", "night", "nova", "omega", "open", "optic", "ozone", "peak", "pixel",
    "power", "prime", "pro", "pulse", "quad", "quantum", "quest", "radar", "raid", "rank",
    "reach", "relic", "rise", "robot", "rouge", "royal", "ruby", "rush", "saber", "sage",
    "scan", "scope", "secret", "sense", "shadow", "shell", "signal", "silver", "sky", "smart",
    "solid", "soul", "space", "spark", "speed", "sphere", "spirit", "star", "steel", "storm",
    "summit", "super", "swift", "synapse", "synergy", "tact", "tag", "talk", "tech", "theta",
    "tidal", "tiger", "time", "titan", "token", "top", "track", "trail", "trap", "trend",
    "trix", "turbo", "ultra", "unity", "urban", "valor", "vanguard", "vertex", "vibe", "vision",
    "vital", "void", "volt", "vortex", "wave", "web", "wing", "wise", "wolf", "xeno",
    "yeti", "yield", "zero", "zeta", "zone", "zoom"
]

FALLBACK_WORDS_AR = [
    "Ù…Ø³ØªØ®Ø¯Ù…", "Ù…Ø³Ø¤ÙˆÙ„", "ØªÙ‚Ù†ÙŠØ©", "Ù…Ø­ØªØ±Ù", "Ù„Ø¹Ø¨Ø©", "Ø¨ÙˆØª", "Ø£Ø¯Ø§Ø©", "Ù…Ø¨Ø¯Ø¹", "Ø±Ù‚Ù…ÙŠ",
    "Ø®Ø¨ÙŠØ±", "Ø¹Ø§Ù„Ù…", "Ù†Ø¸Ø§Ù…", "Ø£ÙÙ‚", "Ù†Ø¬Ù…", "Ø¨ÙˆØ§Ø¨Ø©", "Ø±ÙˆØ­", "Ù‚ÙˆØ©", "ÙØ§Ø±Ø³", "Ø¨Ø·Ù„",
    "Ø°ÙƒÙŠ", "Ø³Ø±ÙŠØ¹", "Ø¬Ø¯ÙŠØ¯", "ÙƒØ¨ÙŠØ±", "Ù‚Ù†Ø§Ø©", "Ù…Ø¬Ù…ÙˆØ¹Ø©", "Ù…Ø³ØªÙ‚Ø¨Ù„", "Ø­ÙŠØ§Ø©", "Ø¹Ù„Ù…",
    "ÙÙ†", "Ù†ÙˆØ±", "ØµØ¯ÙŠÙ‚", "Ù†ØµÙŠØ­Ø©", "ÙÙƒØ±Ø©", "Ø³Ø±", "Ø­Ø±ÙŠØ©", "Ù†Ø¬Ø§Ø­", "Ø£Ù…Ù„", "Ø·Ù…ÙˆØ­"
]


# --- Translations Dictionary (Merged and unified structure) ---
translations = {
    'en': {
        'welcome': "Welcome to RipperTek Bot. Please choose:",
        'generate_username_btn': "ðŸ”¤ Generate Username",
        'generate_word_btn': "ðŸ“š Generate Word (EN/AR)",
        'bulk_check_btn': "ðŸ“„ Bulk Check List",
        'how_to_btn': "â“ How To",
        'language_btn': "ðŸŒ Language / Ø§Ù„Ù„ØºØ©",
        'english_btn': "English",
        'arabic_btn': "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        'language_selection': "Please choose your language:",
        'language_set': "Language set to English.",
        'how_many_names': "How many names would you like to generate and check (1-500)?",
        'invalid_number': "Please enter a number between 1 and 500.",
        'send_pattern': "Send a sample pattern (e.g., `user_x_x_x` where 'x' is replaced by random chars/digits). For fixed parts, enclose them in double quotes (e.g., `\"my_name\"_x`):",
        'invalid_pattern': "Please provide a valid pattern.",
        'ask_delay': "Enter a delay between checks in seconds (e.g., 0.1 for 100ms, 1 for 1s). Enter 0 for no additional delay:",
        'invalid_delay': "Please enter a valid number for delay (e.g., 0.1, 1, 5).",
        'searching_names': "Searching for {count} usernames based on '{pattern}', please wait...",
        'checking_progress': "Checking... {current_checked}/{total_to_check} processed. Remaining: {remaining_count}\nâœ… Available: {available_count}\nâŒ Taken: {taken_count}\n\n(Updates may be delayed due to Telegram's limits)",
        'large_request_warning': "âš ï¸ Warning: Checking a large number of names might take a long time and could sometimes lead to timeouts or forced pauses due to Telegram's rate limits.",
        'checked_variations': "Checked {total_checked} variations for pattern '{pattern}'.\n",
        'available_names': "âœ… Available ({count}):",
        'no_available_names': "ðŸ˜” No available usernames found among the generated ones.",
        'taken_names': "\nâŒ Taken ({count}):",
        'all_generated_available': "\nðŸŽ‰ All generated variations were found available! (Unlikely for large numbers)",
        'result_too_long': "Result too long to display fully. Showing summary:\nTotal checked: {total_checked}\nâœ… Available: {available_count}\nâŒ Taken: {taken_count}\n\nTry a smaller generation count for full list display, or use Bulk Check for specific lists.",
        'download_available_btn': "â¬‡ï¸ Download Available Names",
        'download_all_checked_btn': "â¬‡ï¸ Download All Checked Names",
        'back_btn': "â¬…ï¸ Back",
        'stop_btn': "ðŸ›‘ Stop and Show Results",
        'send_list_usernames': "Send a list of usernames (one per line):",
        'no_usernames_provided': "Please provide a list of usernames.",
        'checking_list': "Checking your list, please wait...",
        'checked_list_usernames': "Checked {total_checked} usernames from your list.\n",
        'none_available_in_list': "ðŸ˜” None of the provided usernames are available.",
        'all_provided_available': "\nðŸŽ‰ All provided usernames were found available! (Unlikely for large numbers)",
        'list_result_too_long': "Result too long to display fully. Showing summary:\nTotal checked: {total_checked}\nâœ… Available: {available_count}\nâŒ Taken: {taken_count}\n\nConsider smaller lists for full display.",
        'operation_cancelled': "âŒ Operation cancelled. Type /start to begin again.",
        'no_names_to_save': "No names to save in {filename}.",
        'failed_to_send_file': "Failed to send the file: {error}",
        'how_to_content': (
            "**How RipperTek Bot Works:**\n\n"
            "This bot helps you find available Telegram usernames. "
            "You can either:\n\n"
            "1. **Generate Usernames:** First, tell me how many names to find, then provide a pattern like `user_x_x_x` (where 'x' is a placeholder that will be replaced by random letters/digits). Use double quotes `\"\"` for fixed parts (e.g., `\"my_name\"_x` will keep \"my_name\" as is). The bot will generate variations and check their availability.\n\n"
            "2. **Bulk Check List:** Send a list of usernames (one per line) and the bot will check each one for availability.\n\n"
            "**Aim:** To simplify the process of finding unique and unused Telegram usernames for your channels, groups, or personal profiles.\n\n"
            "**Important Note on Accuracy:** Username availability checks are performed using Telegram's bot API (specifically, by attempting to retrieve chat information). While this method is generally accurate for public usernames, **it may not be 100% precise for all cases.** Some usernames might appear available through the bot but are actually taken by private entities or certain types of accounts, due to limitations in what bot APIs can check. **Always confirm availability directly on Telegram when attempting to set a username.**"
        ),
        'flood_wait_message': "â—ï¸ Bot paused due to Telegram's flood control. Retrying in {retry_after} seconds. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±ØŒ Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©.",
        'stopping_process_ack': "ðŸ›‘ Stopping... Results will be shown shortly.",
        'found_available_immediate': "ðŸŽ‰ Available now: {username}",
        'file_created': "ðŸ“ Results saved to file", # Added from first bot, and used generally

        # Word Generator Translations
        'welcome_word_gen': "ðŸŽ‰ Welcome to Word Generator Bot!\n\nI can generate real English or Arabic words based on your specifications:\nâ€¢ Choose word length\nâ€¢ Set specific letters at positions\nâ€¢ Control how many words you want\nâ€¢ Save results to a file\n\nChoose an option below:",
        'main_menu_word_gen': "ðŸ“‡ Word Generator Main Menu\n\nWhat would you like to do?",
        'generate_by_length': "ðŸ“ Generate by Length",
        'generate_by_formula': "âš™ï¸ Generate by Formula",
        'ask_length': "Please enter the word length (number of letters):\n\nExample: 5 for 5-letter words (1-20)",
        'ask_formula': "Enter your formula pattern:\n\nFormula syntax:\nâ€¢ x = any letter\nâ€¢ \"text\" = fixed text (use quotes)\nâ€¢ 0 = any symbol or number\nâ€¢ digit = must be that digit\n\nExamples:\nâ€¢ \"L\"xxx\"e\" â†’ 5-letter words starting with L, ending with e\nâ€¢ xx\"o\"x â†’ 4-letter words with 'o' as 3rd letter\nâ€¢ \"th\"xxx â†’ 5-letter words starting with 'th'\nâ€¢ xx0x â†’ 4-letter words with symbol/number as 3rd character\n\nEnter your formula:",
        'ask_count_words': "How many words would you like? (1-500)",
        'invalid_word_length': "ðŸš« Please enter a valid number between 1 and 20.",
        'invalid_word_count': "ðŸš« Please enter a valid number between 1 and 500.",
        'invalid_formula': "ðŸš« Invalid formula format. Please use quotes for fixed text and x for variable letters. Example: \"L\"xxx\"e\"",
        'generating_words': "â³ Generating words... Please wait",
        'no_words_found': "ðŸ˜” No words found matching your criteria. Try different specifications.",
        'results_header': "âœ… Found {count} words:\n\n",
        'download_words_btn': "ðŸ’¾ Download Words",
        'show_more': "ðŸ“– Show More",
        'word_file_created': "ðŸ“ Results saved to file",
        'word_error_creating_file': "âŒ Error creating file"
    },
    'ar': {
        'welcome': "Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø¨ÙˆØª RipperTek. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±:",
        'generate_username_btn': "ðŸ”¤ ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ù…Ø³ØªØ®Ø¯Ù…",
        'generate_word_btn': "ðŸ“š ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ù…Ø© (Ø¹Ø±Ø¨ÙŠ/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ)",
        'bulk_check_btn': "ðŸ“„ ÙØ­Øµ Ù‚Ø§Ø¦Ù…Ø© Ø¬Ù…Ø§Ø¹ÙŠØ©",
        'how_to_btn': "â“ ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…",
        'language_btn': "ðŸŒ Ø§Ù„Ù„ØºØ© / Language",
        'english_btn': "English",
        'arabic_btn': "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        'language_selection': "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ù„ØºØªÙƒ:",
        'language_set': "ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù„ØºØ© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.",
        'how_many_names': "ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªÙŠ ØªÙˆØ¯ ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ ÙˆÙØ­ØµÙ‡Ø§ (1-500)ØŸ",
        'invalid_number': "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… Ø¨ÙŠÙ† 1 Ùˆ 500.",
        'send_pattern': "Ø£Ø±Ø³Ù„ Ù†Ù…Ø·Ø§Ù‹ Ù…Ø«Ø§Ù„ÙŠØ§Ù‹ (Ù…Ø«Ù„ `user_x_x_x` Ø­ÙŠØ« ÙŠØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„ 'x' Ø¨Ø£Ø­Ø±Ù/Ø£Ø±Ù‚Ø§Ù… Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©). Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ø§Ù…ØªÙŠ Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³ `\"\"` Ù„Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø«Ø§Ø¨ØªØ© (Ù…Ø«Ø§Ù„: `\"my_name\"_x` Ø³ÙŠØ¨Ù‚ÙŠ \"my_name\" ÙƒÙ…Ø§ Ù‡ÙŠ):",
        'invalid_pattern': "Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªÙˆÙÙŠØ± Ù†Ù…Ø· ØµØ§Ù„Ø­.",
        'ask_delay': "Ø£Ø¯Ø®Ù„ ØªØ£Ø®ÙŠØ±Ø§Ù‹ Ø¨ÙŠÙ† Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ÙØ­Øµ Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ (Ù…Ø«Ø§Ù„: 0.1 Ù„Ù€ 100 Ù…Ù„Ù„ÙŠ Ø«Ø§Ù†ÙŠØ©ØŒ 1 Ù„Ù€ 1 Ø«Ø§Ù†ÙŠØ©). Ø£Ø¯Ø®Ù„ 0 Ù„Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ ØªØ£Ø®ÙŠØ± Ø¥Ø¶Ø§ÙÙŠ:",
        'invalid_delay': "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ§Ù„Ø­ Ù„Ù„ØªØ£Ø®ÙŠØ± (Ù…Ø«Ø§Ù„: 0.1, 1, 5).",
        'searching_names': "Ø¬Ø§Ø±Ù Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {count} Ø§Ø³Ù… Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ '{pattern}'ØŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...",
        'checking_progress': "Ø¬Ø§Ø±Ù Ø§Ù„ÙØ­Øµ... {current_checked} Ù…Ù† {total_to_check} Ø§Ø³Ù… ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡.\nâœ… Ù…ØªØ§Ø­: {available_count}\nâŒ Ù…Ø­Ø¬ÙˆØ²: {taken_count}\n\n(Ù‚Ø¯ ØªØªØ£Ø®Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø¨Ø³Ø¨Ø¨ Ù‚ÙŠÙˆØ¯ ØªÙ„ØºØ±Ø§Ù…)",
        'large_request_warning': "âš ï¸ ØªØ­Ø°ÙŠØ±: ÙØ­Øµ Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªØ§Ù‹ Ø·ÙˆÙŠÙ„Ø§Ù‹ ÙˆÙ‚Ø¯ ÙŠØ¤Ø¯ÙŠ Ø£Ø­ÙŠØ§Ù†Ø§Ù‹ Ø¥Ù„Ù‰ Ù…Ù‡Ù„Ø© Ø£Ùˆ ØªÙˆÙ‚Ù Ø¥Ø¬Ø¨Ø§Ø±ÙŠ Ø¨Ø³Ø¨Ø¨ Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù…Ù† ØªÙ„ØºØ±Ø§Ù….",
        'checked_variations': "ØªÙ… ÙØ­Øµ {total_checked} Ø§Ø®ØªÙ„Ø§ÙØ§Ù‹ Ù„Ù„Ù†Ù…Ø· '{pattern}'.\n",
        'available_names': "âœ… Ù…ØªØ§Ø­ ({count}):",
        'no_available_names': "ðŸ˜” Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…ØªØ§Ø­Ø© Ø¶Ù…Ù† Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªÙŠ ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡Ø§.",
        'taken_names': "\nâŒ Ù…Ø­Ø¬ÙˆØ² ({count}):",
        'all_generated_available': "\nðŸŽ‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ ÙˆÙØ¬Ø¯Øª Ù…ØªØ§Ø­Ø©! (ØºÙŠØ± Ù…Ø±Ø¬Ø­ Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©)",
        'result_too_long': "Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ø¹Ø±Ø¶Ù‡Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„. Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ:\nØ¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ÙØ­ÙˆØµ: {total_checked}\nâœ… Ù…ØªØ§Ø­: {available_count}\nâŒ Ù…Ø­Ø¬ÙˆØ²: {taken_count}\n\nØ¬Ø±Ø¨ Ø¹Ø¯Ø¯Ø§Ù‹ Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ØŒ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙØ­Øµ Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠ Ù„Ù‚ÙˆØ§Ø¦Ù… Ù…Ø­Ø¯Ø¯Ø©.",
        'download_available_btn': "â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ØªØ§Ø­Ø©",
        'download_all_checked_btn': "â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙØ­ÙˆØµØ©",
        'back_btn': "â¬…ï¸ Ø±Ø¬ÙˆØ¹",
        'stop_btn': "ðŸ›‘ Ø¥ÙŠÙ‚Ø§Ù ÙˆØ¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬",
        'send_list_usernames': "Ø£Ø±Ø³Ù„ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† (Ø§Ø³Ù… ÙˆØ§Ø­Ø¯ ÙÙŠ ÙƒÙ„ Ø³Ø·Ø±):",
        'no_usernames_provided': "Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªÙˆÙÙŠØ± Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†.",
        'checking_list': "Ø¬Ø§Ø±Ù ÙØ­Øµ Ù‚Ø§Ø¦Ù…ØªÙƒØŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...",
        'checked_list_usernames': "ØªÙ… ÙØ­Øµ {total_checked} Ø§Ø³Ù… Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ù‚Ø§Ø¦Ù…ØªÙƒ.\n",
        'none_available_in_list': "ðŸ˜” Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£ÙŠ Ù…Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªÙŠ Ù‚Ø¯Ù…ØªÙ‡Ø§.",
        'all_provided_available': "\nðŸŽ‰ Ø¬Ù…ÙŠØ¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙˆÙØ¬Ø¯Øª Ù…ØªØ§Ø­Ø©! (ØºÙŠØ± Ù…Ø±Ø¬Ø­ Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©)",
        'list_result_too_long': "Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ø¹Ø±Ø¶Ù‡Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„. Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ:\nØ¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ÙØ­ÙˆØµ: {total_checked}\nâœ… Ù…ØªØ§Ø­: {available_count}\nâŒ Ù…Ø­Ø¬ÙˆØ²: {taken_count}\n\nØ§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø± ÙÙŠ Ù‚ÙˆØ§Ø¦Ù… Ø£ØµØºØ± Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙƒØ§Ù…Ù„.",
        'operation_cancelled': "âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©. Ø§ÙƒØªØ¨ /start Ù„Ù„Ø¨Ø¯Ø¡ Ù…Ù† Ø¬Ø¯ÙŠØ¯.",
        'no_names_to_save': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ù„Ø­ÙØ¸Ù‡Ø§ ÙÙŠ {filename}.",
        'failed_to_send_file': "ÙØ´Ù„ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù: {error}",
        'how_to_content': (
            "**ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ Ø¨ÙˆØª RipperTek:**\n\n"
            "ÙŠØ³Ø§Ø¹Ø¯Ùƒ Ù‡Ø°Ø§ Ø§Ù„Ø¨ÙˆØª ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…ØªØ§Ø­Ø© ÙÙŠ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…. "
            "ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù…Ø§:\n\n"
            "1. **ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†:** Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø£Ø®Ø¨Ø±Ù†ÙŠ ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§ØŒ Ø«Ù… Ù‚Ø¯Ù… Ù†Ù…Ø·Ø§Ù‹ Ù…Ø«Ù„ `user_x_x_x` (Ø­ÙŠØ« ÙŠØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„ 'x' Ø¨Ø£Ø­Ø±Ù/Ø£Ø±Ù‚Ø§Ù… Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©). Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ø§Ù…ØªÙŠ Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³ `\"\"` Ù„Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø«Ø§Ø¨ØªØ© (Ù…Ø«Ø§Ù„: `\"my_name\"_x` Ø³ÙŠØ¨Ù‚ÙŠ \"my_name\" ÙƒÙ…Ø§ Ù‡ÙŠ). Ø³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø¨ÙˆØª Ø¨ØªÙˆÙ„ÙŠØ¯ Ø§Ø®ØªÙ„Ø§ÙØ§Øª ÙˆÙØ­Øµ ØªÙˆÙØ±Ù‡Ø§.\n\n"
            "2. **ÙØ­Øµ Ù‚Ø§Ø¦Ù…Ø© Ø¬Ù…Ø§Ø¹ÙŠØ©:** Ø£Ø±Ø³Ù„ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† (Ø§Ø³Ù… ÙˆØ§Ø­Ø¯ ÙÙŠ ÙƒÙ„ Ø³Ø·Ø±) ÙˆØ³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø¨ÙˆØª Ø¨ÙØ­Øµ ÙƒÙ„ Ø§Ø³Ù… Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ±Ù‡.\n\n"
            "**Ø§Ù„Ù‡Ø¯Ù:** ØªØ¨Ø³ÙŠØ· Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙØ±ÙŠØ¯Ø© ÙˆØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù„Ù‚Ù†ÙˆØ§ØªÙƒ Ø£Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ø§ØªÙƒ Ø£Ùˆ Ù…Ù„ÙØ§ØªÙƒ Ø§Ù„Ø´Ø®ØµÙŠØ©.\n\n"
            "**Ù…Ù„Ø§Ø­Ø¸Ø© Ù‡Ø§Ù…Ø© Ø­ÙˆÙ„ Ø§Ù„Ø¯Ù‚Ø©:** ÙŠØªÙ… Ø¥Ø¬Ø±Ø§Ø¡ ÙØ­ÙˆØµØ§Øª ØªÙˆÙØ± Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø¨ÙˆØª ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… (Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ Ø§Ù„ØªØ­Ø¯ÙŠØ¯ØŒ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ±Ø¯Ø§Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©). Ø¨ÙŠÙ†Ù…Ø§ Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø¯Ù‚ÙŠÙ‚Ø© Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¹Ø§Ù…Ø©ØŒ **Ù‚Ø¯ Ù„Ø§ ØªÙƒÙˆÙ† Ø¯Ù‚ÙŠÙ‚Ø© Ø¨Ù†Ø³Ø¨Ø© 100% ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª.** Ù‚Ø¯ ØªØ¸Ù‡Ø± Ø¨Ø¹Ø¶ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…ØªØ§Ø­Ø© Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„Ø¨ÙˆØª ÙˆÙ„ÙƒÙ†Ù‡Ø§ ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ Ù…Ø­Ø¬ÙˆØ²Ø© Ø¨ÙˆØ§Ø³Ø·Ø© ÙƒÙŠØ§Ù†Ø§Øª Ø®Ø§ØµØ© Ø£Ùˆ Ø£Ù†ÙˆØ§Ø¹ Ù…Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨Ø§ØªØŒ Ø¨Ø³Ø¨Ø¨ Ù‚ÙŠÙˆØ¯ ÙÙŠ Ù…Ø§ ÙŠÙ…ÙƒÙ† Ù„ÙˆØ§Ø¬Ù‡Ø§Øª Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø¨ÙˆØª ÙØ­ØµÙ‡Ø§. **ØªØ£ÙƒØ¯ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù…Ù† Ø§Ù„ØªÙˆÙØ± Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù„Ù‰ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø¹Ù†Ø¯ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ø³Ù… Ù…Ø³ØªØ®Ø¯Ù….**"
        ),
        'flood_wait_message': "â—ï¸ Bot paused due to Telegram's flood control. Retrying in {retry_after} seconds. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±ØŒ Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©.",
        'stopping_process_ack': "ðŸ›‘ Ø¬Ø§Ø±Ù Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù... Ø³ØªØ¸Ù‡Ø± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù‚Ø±ÙŠØ¨Ø§Ù‹.",
        'found_available_immediate': "ðŸŽ‰ Ù…ØªØ§Ø­ Ø§Ù„Ø¢Ù†: {username}",
        'file_created': "ðŸ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ù…Ù„Ù", # Added from first bot, and used generally

        # Word Generator Translations
        'welcome_word_gen': "ðŸŽ‰ Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø¨ÙˆØª Ù…ÙˆÙ„Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª!\n\nÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø¥Ù†Ø´Ø§Ø¡ ÙƒÙ„Ù…Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø£Ùˆ Ø¹Ø±Ø¨ÙŠØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø­Ø³Ø¨ Ù…ÙˆØ§ØµÙØ§ØªÙƒ:\nâ€¢ Ø§Ø®ØªØ± Ø·ÙˆÙ„ Ø§Ù„ÙƒÙ„Ù…Ø©\nâ€¢ Ø­Ø¯Ø¯ Ø£Ø­Ø±Ù Ù…Ø¹ÙŠÙ†Ø© ÙÙŠ Ù…ÙˆØ§Ø¶Ø¹ Ù…Ø­Ø¯Ø¯Ø©\nâ€¢ ØªØ­ÙƒÙ… ÙÙŠ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\nâ€¢ Ø§Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù\n\nØ§Ø®ØªØ± Ø®ÙŠØ§Ø±Ø§Ù‹ Ù…Ù† Ø§Ù„Ø£Ø³ÙÙ„:",
        'main_menu_word_gen': "ðŸ“‡ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù…ÙˆÙ„Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª\n\nÙ…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø£Ù† ØªÙØ¹Ù„ØŸ",
        'generate_by_length': "ðŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„Ø·ÙˆÙ„",
        'generate_by_formula': "âš™ï¸ Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©",
        'ask_length': "Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ Ø·ÙˆÙ„ Ø§Ù„ÙƒÙ„Ù…Ø© (Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù):\n\nÙ…Ø«Ø§Ù„: 5 Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙƒÙˆÙ†Ø© Ù…Ù† 5 Ø£Ø­Ø±Ù (1-20)",
        'ask_formula': "Ø£Ø¯Ø®Ù„ Ù†Ù…Ø· Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©:\n\nØµÙŠØºØ© Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©:\nâ€¢ x = Ø£ÙŠ Ø­Ø±Ù\nâ€¢ \"Ù†Øµ\" = Ù†Øµ Ø«Ø§Ø¨Øª (Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙ†ØµÙŠØµ)\nâ€¢ 0 = Ø£ÙŠ Ø±Ù…Ø² Ø£Ùˆ Ø±Ù‚Ù…\nâ€¢ Ø±Ù‚Ù… = ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ø§Ù„Ø±Ù‚Ù…\n\nØ£Ù…Ø«Ù„Ø©:\nâ€¢ \"Ø§\"xxx\"Ø©\" â†’ ÙƒÙ„Ù…Ø§Øª Ù…Ù† 5 Ø£Ø­Ø±Ù ØªØ¨Ø¯Ø£ Ø¨Ù€ Ø§ ÙˆØªÙ†ØªÙ‡ÙŠ Ø¨Ù€ Ø©\nâ€¢ xx\"Ùˆ\"x â†’ ÙƒÙ„Ù…Ø§Øª Ù…Ù† 4 Ø£Ø­Ø±Ù Ù…Ø¹ 'Ùˆ' ÙƒØ§Ù„Ø­Ø±Ù Ø§Ù„Ø«Ø§Ù„Ø«\nâ€¢ \"Ø§Ù„\"xxx â†’ ÙƒÙ„Ù…Ø§Øª Ù…Ù† 5 Ø£Ø­Ø±Ù ØªØ¨Ø¯Ø£ Ø¨Ù€ 'Ø§Ù„'\nâ€¢ xx0x â†’ ÙƒÙ„Ù…Ø§Øª Ù…Ù† 4 Ø£Ø­Ø±Ù Ù…Ø¹ Ø±Ù…Ø²/Ø±Ù‚Ù… ÙƒØ§Ù„Ø­Ø±Ù Ø§Ù„Ø«Ø§Ù„Ø«\n\nØ£Ø¯Ø®Ù„ Ù…Ø¹Ø§Ø¯Ù„ØªÙƒ:",
        'ask_count_words': "ÙƒÙ… ÙƒÙ„Ù…Ø© ØªØ±ÙŠØ¯ØŸ (1-500)",
        'invalid_word_length': "ðŸš« Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ Ø±Ù‚Ù…Ø§Ù‹ ØµØ­ÙŠØ­Ø§Ù‹ Ø¨ÙŠÙ† 1 Ùˆ 20.",
        'invalid_word_count': "ðŸš« Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ Ø±Ù‚Ù…Ø§Ù‹ ØµØ­ÙŠØ­Ø§Ù‹ Ø¨ÙŠÙ† 1 Ùˆ 500.",
        'invalid_formula': "ðŸš« ØµÙŠØºØ© Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© ØºÙŠØ± ØµØ­ÙŠØ­Ø©. Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙ†ØµÙŠØµ Ù„Ù„Ù†Øµ Ø§Ù„Ø«Ø§Ø¨Øª Ùˆ x Ù„Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù…ØªØºÙŠØ±Ø©. Ù…Ø«Ø§Ù„: \"Ø§\"xxx\"Ø©\"",
        'generating_words': "â³ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒÙ„Ù…Ø§Øª... Ù…Ù† ÙØ¶Ù„Ùƒ Ø§Ù†ØªØ¸Ø±",
        'no_words_found': "ðŸ˜” Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ø§ÙŠÙŠØ±Ùƒ. Ø¬Ø±Ø¨ Ù…ÙˆØ§ØµÙØ§Øª Ù…Ø®ØªÙ„ÙØ©.",
        'results_header': "âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {count} ÙƒÙ„Ù…Ø©:\n\n",
        'download_words_btn': "ðŸ’¾ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª",
        'show_more': "ðŸ“– Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø²ÙŠØ¯",
        'word_file_created': "ðŸ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ù…Ù„Ù",
        'word_error_creating_file': "âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù"
    }
}


# --- Helper function to get translated text ---
def get_text(context: ContextTypes.DEFAULT_TYPE, key: str, **kwargs) -> str:
    lang = context.user_data.get('language', 'en')
    text = translations.get(lang, translations['en']).get(key, f"Translation missing for '{key}' in '{lang}'")
    return text.format(**kwargs)

# Helper function to escape characters for MarkdownV2
def escape_markdown_v2(text: str) -> str:
    """Helper function to escape characters for MarkdownV2."""
    special_chars = r'_*[]()~`>#+-=|{}.!'
    text = text.replace('\\', '\\\\')
    for char in special_chars:
        text = text.replace(char, f'\\{char}')
    return text


# --- Helper Functions for Keyboards ---
def get_main_menu_keyboard(context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton(get_text(context, 'generate_username_btn'), callback_data='generate_username')],
        [InlineKeyboardButton(get_text(context, 'generate_word_btn'), callback_data='generate_word')],
        [InlineKeyboardButton(get_text(context, 'bulk_check_btn'), callback_data='bulk')],
        [InlineKeyboardButton(get_text(context, 'how_to_btn'), callback_data='how_to')],
        [InlineKeyboardButton(get_text(context, 'language_btn'), callback_data='set_language')]
    ]
    return InlineKeyboardMarkup(keyboard)

def get_word_gen_menu_keyboard(context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton(get_text(context, 'generate_by_length'), callback_data='word_gen_length')],
        [InlineKeyboardButton(get_text(context, 'generate_by_formula'), callback_data='word_gen_formula')],
        [InlineKeyboardButton(get_text(context, 'back_btn'), callback_data='back_to_main_menu')],
        [InlineKeyboardButton(get_text(context, 'stop_btn'), callback_data='stop_processing')]
    ]
    return InlineKeyboardMarkup(keyboard)

def get_stop_and_back_keyboard(context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton(get_text(context, 'back_btn'), callback_data='back_to_main_menu')],
        [InlineKeyboardButton(get_text(context, 'stop_btn'), callback_data='stop_processing')]
    ]
    return InlineKeyboardMarkup(keyboard)

def get_result_screen_keyboard(context: ContextTypes.DEFAULT_TYPE, for_words: bool = False):
    if for_words:
        keyboard = [
            [InlineKeyboardButton(get_text(context, 'download_words_btn'), callback_data='download_words')],
            [InlineKeyboardButton(get_text(context, 'back_btn'), callback_data='back_to_word_gen_menu')],
            [InlineKeyboardButton(get_text(context, 'stop_btn'), callback_data='stop_processing')]
        ]
    else: # For username generation
        keyboard = [
            [InlineKeyboardButton(get_text(context, 'download_available_btn'), callback_data='download_available')],
            [InlineKeyboardButton(get_text(context, 'download_all_checked_btn'), callback_data='download_all_checked')],
            [InlineKeyboardButton(get_text(context, 'back_btn'), callback_data='back_to_main_menu')],
            [InlineKeyboardButton(get_text(context, 'stop_btn'), callback_data='stop_processing')]
        ]
    return InlineKeyboardMarkup(keyboard)

def get_language_keyboard():
    keyboard = [
        [InlineKeyboardButton("English", callback_data='lang_en')],
        [InlineKeyboardButton("Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", callback_data='lang_ar')],
        [InlineKeyboardButton("â¬…ï¸ Back", callback_data='back_to_main_menu')]
    ]
    return InlineKeyboardMarkup(keyboard)


# --- Core Logic Functions for Username Generation ---

def is_valid_username(username: str) -> bool:
    if not (MIN_USERNAME_LENGTH <= len(username) <= MAX_USERNAME_LENGTH):
        return False
    if not username[0].isalpha():
        return False
    if not all(c.isalnum() or c == '_' for c in username):
        return False
    return True

def is_valid_pattern_for_generation(pattern: str) -> bool:
    return bool(re.search(r'"[^"]*"|x', pattern))

async def generate_usernames(pattern: str, num_variations_to_try: int = 200, context: ContextTypes.DEFAULT_TYPE = None) -> list[str]:
    letters_digits = string.ascii_lowercase + string.digits + '_'
    generated = set()
    attempts = 0
    max_attempts = num_variations_to_try * 20

    parsed_pattern_parts = []
    regex_tokenizer = re.compile(r'"([^"]*)"|(x+)|([^"x]+)')

    for match in regex_tokenizer.finditer(pattern):
        if match.group(1) is not None:
            parsed_pattern_parts.append(('fixed', match.group(1)))
        elif match.group(2) is not None:
            parsed_pattern_parts.append(('placeholder_block', len(match.group(2))))
        elif match.group(3) is not None:
            parsed_pattern_parts.append(('fixed', match.group(3)))

    logger.info(f"Pattern parsed for generation: {parsed_pattern_parts}")

    has_variable_parts = any(part[0] == 'placeholder_block' for part in parsed_pattern_parts)
    if not has_variable_parts and not parsed_pattern_parts:
        logger.warning(f"Pattern '{pattern}' contains no placeholders or fixed parts for generation.")
        return []

    lang = context.user_data.get('language', 'en') if context else 'en'
    fallback_words = FALLBACK_WORDS_AR if lang == 'ar' else FALLBACK_WORDS_EN

    api_seed_words = []
    if lang == 'en':
        try:
            async with httpx.AsyncClient() as client:
                api_url = "https://random-word-api.vercel.app/api"
                params = {"words": 200}
                response = await client.get(api_url, params=params, timeout=7)
                response.raise_for_status()
                api_seed_words = response.json()
                logger.info(f"Fetched {len(api_seed_words)} words from API for pattern generation.")
        except httpx.RequestError as e:
            logger.error(f"HTTPX Request Error fetching words from API: {e}. Using fallback words.")
        except Exception as e:
            logger.error(f"Unexpected error fetching words from API: {e}. Using fallback words.")

    current_seed_words = api_seed_words + fallback_words
    current_seed_words = list(set(current_seed_words))
    random.shuffle(current_seed_words)

    while len(generated) < num_variations_to_try and attempts < max_attempts:
        current_username_parts = []
        seed_word_used_for_first_x_block = False

        for idx, (part_type, content) in enumerate(parsed_pattern_parts):
            if part_type == 'fixed':
                current_username_parts.append(content)
            elif part_type == 'placeholder_block':
                block_len = content

                previous_part_was_fixed = (idx > 0 and parsed_pattern_parts[idx-1][0] == 'fixed')

                is_first_relevant_x_block = (idx == 0 or previous_part_was_fixed) and \
                                            not seed_word_used_for_first_x_block and \
                                            current_seed_words

                if is_first_relevant_x_block:
                    chosen_word = None
                    prefix_for_word_gen = ""
                    if previous_part_was_fixed:
                        prefix_for_word_gen = parsed_pattern_parts[idx-1][1]
                        if current_username_parts and current_username_parts[-1] == prefix_for_word_gen:
                            current_username_parts.pop()

                    candidate_words_for_block = []
                    for word in current_seed_words:
                        word_lower = word.lower()
                        prefix_lower = prefix_for_word_gen.lower()

                        if word_lower.startswith(prefix_lower) and word[0].isalpha():
                            remaining_word_len_from_word = len(word) - len(prefix_for_word_gen)

                            remaining_pattern_min_len = 0
                            for subsequent_part_type, subsequent_content in parsed_pattern_parts[idx+1:]:
                                if subsequent_part_type == 'fixed':
                                    remaining_pattern_min_len += len(subsequent_content)
                                elif subsequent_part_type == 'placeholder_block':
                                    remaining_pattern_min_len += 1

                            hypothetical_total_len = len("".join(current_username_parts)) + len(word) + max(0, block_len - remaining_word_len_from_word) + remaining_pattern_min_len

                            if MIN_USERNAME_LENGTH <= hypothetical_total_len <= MAX_USERNAME_LENGTH:
                                candidate_words_for_block.append((abs(remaining_word_len_from_word - block_len), word))

                    if candidate_words_for_block:
                        candidate_words_for_block.sort(key=lambda x: x[0])
                        best_fit_diff = candidate_words_for_block[0][0]
                        best_fit_words = [w for diff, w in candidate_words_for_block if diff == best_fit_diff]
                        chosen_word = random.choice(best_fit_words)
                    elif current_seed_words:
                        any_valid_start_words = []
                        for word in current_seed_words:
                            if word[0].isalpha():
                                hypothetical_total_len = len("".join(current_username_parts)) + len(word) + remaining_pattern_min_len
                                if MIN_USERNAME_LENGTH <= hypothetical_total_len <= MAX_USERNAME_LENGTH:
                                    any_valid_start_words.append(word)
                        if any_valid_start_words:
                            chosen_word = random.choice(any_valid_start_words)

                    if chosen_word:
                        current_username_parts.append(chosen_word)
                        seed_word_used_for_first_x_block = True

                        chars_to_fill_in_block = block_len - (len(chosen_word) - len(prefix_for_word_gen))
                        if chars_to_fill_in_block > 0:
                            for _ in range(chars_to_fill_in_block):
                                current_username_parts.append(random.choice(letters_digits))
                    else:
                        if previous_part_was_fixed:
                            current_username_parts.append(prefix_for_word_gen)

                        for _ in range(block_len):
                            if idx == 0 and not current_username_parts:
                                current_username_parts.append(random.choice(string.ascii_lowercase))
                            else:
                                current_username_parts.append(random.choice(letters_digits))

                else:
                    for _ in range(block_len):
                        current_username_parts.append(random.choice(letters_digits))

        final_uname = "".join(current_username_parts)

        if is_valid_username(final_uname):
            generated.add(final_uname)
        attempts += 1

    return list(generated)

async def check_username_availability(update: Update, context: ContextTypes.DEFAULT_TYPE, username: str) -> tuple[bool, str, str | None]:
    if not is_valid_username(username):
        logger.warning(f"Invalid username format (pre-API check): {username}")
        return False, username, None

    try:
        chat = await context.bot.get_chat(f"@{username}")
        logger.info(f"Username @{username} recognized by Telegram API (Chat ID: {chat.id}, Type: {chat.type}). Considered taken/reserved.")
        return False, username, f"https://t.me/{chat.username}" if chat.username else None

    except TimedOut as e:
        retry_after = e.retry_after
        logger.warning(f"FLOODWAIT: Hit flood control for @{username}. Retrying in {retry_after} seconds.")
        try:
            await context.bot.send_message(
                chat_id=update.effective_chat.id,
                text=get_text(context, 'flood_wait_message', retry_after=retry_after)
            )
        except Exception as send_e:
            logger.error(f"Failed to send flood_wait_message: {send_e}")
        await asyncio.sleep(retry_after)
        return await check_username_availability(update, context, username)
    except BadRequest as e:
        error_message = str(e).lower()
        if "username not found" in error_message or "chat not found" in error_message:
            logger.info(f"Username @{username} is likely available (BadRequest: '{error_message}').")
            return True, username, f"https://t.me/{username}"
        else:
            logger.error(f"Telegram API BadRequest for {username} (NOT available, reason: '{error_message}').")
            return False, username, None
    except Exception as e:
        logger.error(f"Unexpected error checking username {username} (assuming NOT available): {e}")
        return False, username, None

async def display_results(update: Update, context: ContextTypes.DEFAULT_TYPE, all_results: list[dict], pattern: str = None, is_bulk: bool = False):
    available_names_info = [r for r in all_results if r['available']]
    taken_names_info = [r for r in all_results if not r['available']]

    context.user_data['last_available_names'] = [r['username'] for r in available_names_info]
    context.user_data['last_all_checked_results'] = all_results

    text_parts = []
    if pattern:
        escaped_pattern_display = escape_markdown_v2(pattern)
        text_parts.append(get_text(context, 'checked_variations', total_checked=len(all_results), pattern=escaped_pattern_display))
    else:
        text_parts.append(get_text(context, 'checked_list_usernames', total_checked=len(all_results)))


    def format_names_for_display(name_objects: list[dict]) -> list[str]:
        formatted = []
        for item in name_objects:
            escaped_username = escape_markdown_v2(item['username'])
            if item['link']:
                formatted.append(f"[`@{escaped_username}`]({item['link']})")
            else:
                formatted.append(f"`@{escaped_username}`")
        return formatted

    if available_names_info:
        text_parts.append(get_text(context, 'available_names', count=len(available_names_info)))
        display_available = format_names_for_display(available_names_info)
        text_parts.append("\n".join(display_available))
        num_to_generate = context.user_data.get('num_to_generate_display', len(available_names_info))
        if len(available_names_info) > num_to_generate:
            remaining = len(available_names_info) - num_to_generate
            text_parts.append(f"...and {remaining} more available names.")
    else:
        text_parts.append(get_text(context, 'no_available_names'))

    if taken_names_info:
        MAX_TAKEN_TO_DISPLAY = 20
        text_parts.append(get_text(context, 'taken_names', count=len(taken_names_info)))
        display_taken = format_names_for_display(taken_names_info[:MAX_TAKEN_TO_DISPLAY])
        text_parts.append("\n".join(display_taken))
        if len(taken_names_info) > MAX_TAKEN_TO_DISPLAY:
            text_parts.append(f"...and {len(taken_names_info) - MAX_TAKEN_TO_DISPLAY} more taken names.")
    else:
        if available_names_info and not taken_names_info:
             text_parts.append(get_text(context, 'all_generated_available'))


    final_text = "\n".join(text_parts)

    if len(final_text) > 4000:
        if is_bulk:
            final_text = get_text(context, 'list_result_too_long', total_checked=len(all_results), available_count=len(available_names_info), taken_count=len(taken_names_info))
        else:
            final_text = get_text(context, 'result_too_long', total_checked=len(all_results), available_count=len(available_names_info), taken_count=len(taken_names_info))

    await update.effective_chat.send_message(final_text, parse_mode='Markdown', reply_markup=get_result_screen_keyboard(context))


async def process_check(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    usernames: list[str],
    pattern: str = None,
    is_bulk: bool = False
):
    all_results = []
    available_count = 0
    taken_count = 0
    chat_id = update.effective_chat.id

    loop = asyncio.get_running_loop()
    last_update_time = loop.time()
    progress_msg_id = None

    warning_text = ""
    if len(usernames) > 100:
        warning_text = get_text(context, 'large_request_warning') + "\n\n"

    try:
        escaped_pattern_for_init_msg = escape_markdown_v2(pattern) if pattern else ""
        initial_message = await update.message.reply_text(
            warning_text + get_text(context, 'searching_names', count=len(usernames), pattern=escaped_pattern_for_init_msg),
            parse_mode='Markdown',
            reply_markup=get_stop_and_back_keyboard(context)
        )
        progress_msg_id = initial_message.message_id
        context.user_data['progress_message_id'] = progress_msg_id
        context.user_data['stop_requested'] = False
    except Exception as e:
        logger.error(f"Failed to send initial progress message: {e}")
        await update.effective_chat.send_message(get_text(context, 'operation_cancelled'))
        return ConversationHandler.END


    check_delay = context.user_data.get('check_delay', 0.05)

    try:
        for i, uname in enumerate(usernames):
            if context.user_data.get('stop_requested'):
                logger.info("Stop requested by user. Breaking loop.")
                break

            is_available, username_str, link = await check_username_availability(update, context, uname)
            all_results.append({'username': username_str, 'available': is_available, 'link': link})

            if is_available:
                try:
                    escaped_username_str = escape_markdown_v2(username_str)
                    msg_text = get_text(context, 'found_available_immediate',
                                         username=f"[`@{escaped_username_str}`]({link})" if link else f"`@{escaped_username_str}`")
                    await update.effective_chat.send_message(msg_text, parse_mode='Markdown')
                except Exception as e:
                    logger.warning(f"Failed to send immediate available name update: {e}")

            if is_available:
                available_count += 1
            else:
                taken_count += 1

            current_time = loop.time()
            if (i + 1) % UPDATE_INTERVAL_COUNT == 0 or (current_time - last_update_time) >= UPDATE_INTERVAL_SECONDS:
                try:
                    await context.bot.edit_message_text(
                        chat_id=chat_id,
                        message_id=progress_msg_id,
                        text=get_text(context, 'checking_progress',
                                      current_checked=i+1,
                                      total_to_check=len(usernames),
                                      available_count=available_count,
                                      taken_count=taken_count,
                                      remaining_count=len(usernames)-(i+1)),
                        parse_mode='Markdown',
                        reply_markup=get_stop_and_back_keyboard(context)
                    )
                    last_update_time = current_time
                except Exception as e:
                    logger.warning(f"Failed to update progress message: {e}")

            try:
                await asyncio.sleep(check_delay)
            except asyncio.CancelledError:
                logger.info("Processing task was cancelled during sleep.")
                break

    except asyncio.CancelledError:
        logger.info("Process check task was externally cancelled.")
    finally:
        if all_results:
            await display_results(update, context, all_results, pattern=pattern, is_bulk=is_bulk)
        else:
            await update.effective_chat.send_message(get_text(context, 'operation_cancelled'))

    return ConversationHandler.END


# --- Core Logic Functions for Word Generation ---

def filter_words_by_length(words: Set[str], length: int) -> List[str]:
    """Filter words by exact length"""
    return [word for word in words if len(word) == length]

def parse_formula_pattern(formula: str) -> Dict:
    """Parse formula pattern like 'L'xxx'e' or xx'o'x"""
    try:
        constraints = []
        current_pos = 0
        total_length = 0
        i = 0
        while i < len(formula):
            if formula[i] == '"':
                j = i + 1
                while j < len(formula) and formula[j] != '"':
                    j += 1
                if j < len(formula):
                    fixed_text = formula[i+1:j].lower()
                    constraints.append({
                        'type': 'fixed_text',
                        'position': current_pos,
                        'text': fixed_text
                    })
                    current_pos += len(fixed_text)
                    total_length += len(fixed_text)
                    i = j + 1
                else:
                    return None # Unclosed quote
            elif formula[i].lower() == 'x':
                current_pos += 1
                total_length += 1
                i += 1
            elif formula[i].isdigit():
                constraints.append({
                    'type': 'character_type',
                    'position': current_pos,
                    'char_type': 'digit'
                })
                current_pos += 1
                total_length += 1
                i += 1
            elif formula[i] == '0':
                constraints.append({
                    'type': 'character_type',
                    'position': current_pos,
                    'char_type': 'symbol_or_digit'
                })
                current_pos += 1
                total_length += 1
                i += 1
            else:
                i += 1 # Skip unknown characters
        return {
            'type': 'formula',
            'length': total_length,
            'constraints': constraints
        }
    except Exception as e:
        logger.error(f"Error parsing formula pattern '{formula}': {e}")
        return None

def filter_words_by_pattern(words: Set[str], pattern_dict: Dict) -> List[str]:
    """Filter words based on pattern dictionary"""
    if not pattern_dict:
        return []
    filtered_words = []
    for word in words:
        if pattern_dict['type'] == 'formula':
            if matches_formula(word, pattern_dict):
                filtered_words.append(word)
    return filtered_words

def matches_formula(word: str, pattern_dict: Dict) -> bool:
    """Check if word matches formula pattern"""
    if len(word) != pattern_dict['length']:
        return False
    for constraint in pattern_dict['constraints']:
        if constraint['type'] == 'fixed_text':
            start_pos = constraint['position']
            end_pos = start_pos + len(constraint['text'])
            if end_pos > len(word) or word[start_pos:end_pos] != constraint['text']:
                return False
        elif constraint['type'] == 'character_type':
            pos = constraint['position']
            if pos >= len(word):
                return False
            char = word[pos]
            if constraint['char_type'] == 'digit':
                if not char.isdigit():
                    return False
            elif constraint['char_type'] == 'symbol_or_digit':
                if char.isalpha(): # It must NOT be an alphabet char
                    return False
    return True

def generate_words(length: int = None, formula: str = None, count: int = 10, language: str = 'en') -> List[str]:
    """Generate words based on criteria"""
    if language == 'ar':
        words = ARABIC_WORDS.copy()
    else:
        words = ENGLISH_WORDS.copy()

    if length:
        words = set(filter_words_by_length(words, length))

    if formula:
        pattern_dict = parse_formula_pattern(formula)
        if pattern_dict:
            words = set(filter_words_by_pattern(words, pattern_dict))
        else:
            logger.warning(f"Invalid formula '{formula}', skipping formula filtering.")

    word_list = list(words)
    random.shuffle(word_list)
    return word_list[:count]


# --- Main Handler Functions ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if 'language' not in context.user_data:
        context.user_data['language'] = 'en'
    context.user_data['stop_requested'] = False
    await update.message.reply_text(get_text(context, 'welcome'), reply_markup=get_main_menu_keyboard(context))
    return INITIAL_MENU

async def handle_button_callbacks(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    if query.data == 'generate_username':
        await query.edit_message_text(get_text(context, 'how_many_names'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_USERNAME_COUNT
    elif query.data == 'generate_word':
        await query.edit_message_text(get_text(context, 'main_menu_word_gen'), reply_markup=get_word_gen_menu_keyboard(context))
        return ASK_WORD_LENGTH
    elif query.data == 'bulk':
        await query.edit_message_text(get_text(context, 'send_list_usernames'), reply_markup=get_stop_and_back_keyboard(context))
        return BULK_LIST
    elif query.data == 'how_to':
        await query.edit_message_text(
            get_text(context, 'how_to_content'),
            parse_mode='Markdown',
            reply_markup=get_stop_and_back_keyboard(context)
        )
        return HOW_TO_INFO
    elif query.data == 'set_language':
        await query.edit_message_text(get_text(context, 'language_selection'), reply_markup=get_language_keyboard())
        return SET_LANGUAGE
    elif query.data.startswith('lang_'):
        return await set_language_callback(update, context)

    # File download callbacks (for username results)
    elif query.data == 'download_available':
        if 'last_available_names' in context.user_data and context.user_data['last_available_names']:
            await send_names_as_file(context, update.effective_chat.id, context.user_data['last_available_names'], "available_usernames.txt")
        else:
            await query.message.reply_text(get_text(context, 'no_names_to_save', filename="available_usernames.txt"))
        await query.edit_message_text(get_text(context, 'welcome'), reply_markup=get_main_menu_keyboard(context))
        return INITIAL_MENU

    elif query.data == 'download_all_checked':
        if 'last_all_checked_results' in context.user_data and context.user_data['last_all_checked_results']:
            formatted_results = []
            for item in context.user_data['last_all_checked_results']:
                status_key = 'available_names' if item['available'] else 'taken_names'
                status_text = translations[context.user_data['language']].get(status_key, translations['en'][status_key])
                clean_status = status_text.replace('âœ… Available (', '').replace('âŒ Taken (', '').replace('):', '').strip()
                formatted_results.append(f"{item['username']} ({clean_status})")
            await send_names_as_file(context, update.effective_chat.id, formatted_results, "all_checked_usernames.txt")
        else:
            await query.message.reply_text(get_text(context, 'no_names_to_save', filename="all_checked_usernames.txt"))
        await query.edit_message_text(get_text(context, 'welcome'), reply_markup=get_main_menu_keyboard(context))
        return INITIAL_MENU

    # Navigation callbacks
    elif query.data == 'back_to_main_menu':
        context.user_data['stop_requested'] = True
        await query.edit_message_text(
            get_text(context, 'welcome'),
            reply_markup=get_main_menu_keyboard(context)
        )
        return INITIAL_MENU
    elif query.data == 'back_to_word_gen_menu':
        await query.edit_message_text(get_text(context, 'main_menu_word_gen'), reply_markup=get_word_gen_menu_keyboard(context))
        return ASK_WORD_LENGTH

    elif query.data == 'stop_processing':
        await stop_processing_callback(update, context)
        return ConversationHandler.END

    # Word generation specific callbacks
    elif query.data == 'word_gen_length':
        await query.edit_message_text(get_text(context, 'ask_length'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_WORD_LENGTH
    elif query.data == 'word_gen_formula':
        await query.edit_message_text(get_text(context, 'ask_formula'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_WORD_FORMULA
    elif query.data == 'download_words': # For word generation results
        if 'last_generated_words' in context.user_data and context.user_data['last_generated_words']:
            await send_names_as_file(context, update.effective_chat.id, context.user_data['last_generated_words'], "generated_words.txt")
        else:
            await query.message.reply_text(get_text(context, 'no_names_to_save', filename="generated_words.txt"))
        await query.edit_message_text(get_text(context, 'main_menu_word_gen'), reply_markup=get_word_gen_menu_keyboard(context))
        return ASK_WORD_LENGTH

    return INITIAL_MENU

async def stop_processing_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer(text=get_text(context, 'stopping_process_ack'))

    context.user_data['stop_requested'] = True

    if 'processing_task' in context.user_data and not context.user_data['processing_task'].done():
        context.user_data['processing_task'].cancel()
        logger.info("Attempted to cancel the ongoing process_check task.")
        try:
            await asyncio.sleep(0.1)
        except asyncio.CancelledError:
            pass

    if 'progress_message_id' in context.user_data:
        try:
            await context.bot.edit_message_text(
                chat_id=query.message.chat_id,
                message_id=context.user_data['progress_message_id'],
                text=get_text(context, 'stopping_process_ack'),
                reply_markup=None
            )
        except Exception as e:
            logger.warning(f"Failed to edit message to acknowledge stop: {e}")

    try:
        await query.message.reply_text(
            get_text(context, 'welcome'),
            reply_markup=get_main_menu_keyboard(context)
        )
    except Exception as e:
        logger.error(f"Failed to send main menu after stop: {e}")

    return ConversationHandler.END


async def set_language_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    lang_code = query.data.split('_')[1]
    context.user_data['language'] = lang_code

    await query.edit_message_text(get_text(context, 'language_set'), reply_markup=get_main_menu_keyboard(context))
    return INITIAL_MENU


# --- Handlers for Username Generation Flow ---
async def handle_username_count_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        count = int(update.message.text.strip())
        if not (1 <= count <= 500):
            await update.message.reply_text(get_text(context, 'invalid_number'), reply_markup=get_stop_and_back_keyboard(context))
            return ASK_USERNAME_COUNT

        context.user_data['num_to_generate_display'] = count
        await update.message.reply_text(get_text(context, 'send_pattern'), parse_mode='Markdown', reply_markup=get_stop_and_back_keyboard(context))
        return ASK_PATTERN
    except ValueError:
        await update.message.reply_text(get_text(context, 'invalid_number'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_USERNAME_COUNT

async def handle_pattern_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    pattern = update.message.text.strip()
    if not pattern or not is_valid_pattern_for_generation(pattern):
        await update.message.reply_text(get_text(context, 'invalid_pattern'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_PATTERN

    context.user_data['pattern'] = pattern
    await update.message.reply_text(get_text(context, 'ask_delay'), reply_markup=get_stop_and_back_keyboard(context))
    return ASK_DELAY

async def handle_delay_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        delay = float(update.message.text.strip())
        if delay < 0:
            raise ValueError
        context.user_data['check_delay'] = delay

        pattern = context.user_data['pattern']
        num_to_display = context.user_data.get('num_to_generate_display', 20)

        generated_names = await generate_usernames(pattern, num_to_display, context)

        if not generated_names:
            await update.message.reply_text(get_text(context, 'no_available_names'), reply_markup=get_stop_and_back_keyboard(context))
            return INITIAL_MENU

        task = asyncio.create_task(
            process_check(
                update=update,
                context=context,
                usernames=generated_names,
                pattern=pattern,
                is_bulk=False
            )
        )
        context.user_data['processing_task'] = task
        return ASK_DELAY

    except ValueError:
        await update.message.reply_text(get_text(context, 'invalid_delay'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_DELAY

async def bulk_list_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    names = [n.strip() for n in update.message.text.splitlines() if n.strip()]
    if not names:
        await update.message.reply_text(get_text(context, 'no_usernames_provided'), reply_markup=get_stop_and_back_keyboard(context))
        return BULK_LIST

    task = asyncio.create_task(
        process_check(
            update=update,
            context=context,
            usernames=names,
            pattern=None,
            is_bulk=True
        )
    )
    context.user_data['processing_task'] = task
    return BULK_LIST


# --- Handlers for Word Generation Flow ---
async def handle_word_length_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        length = int(update.message.text.strip())
        if not (1 <= length <= 20):
            await update.message.reply_text(get_text(context, 'invalid_word_length'), reply_markup=get_stop_and_back_keyboard(context))
            return ASK_WORD_LENGTH

        context.user_data['word_length'] = length
        await update.message.reply_text(get_text(context, 'ask_count_words'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_WORD_COUNT
    except ValueError:
        await update.message.reply_text(get_text(context, 'invalid_word_length'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_WORD_LENGTH

async def handle_word_formula_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    formula = update.message.text.strip()
    pattern_dict = parse_formula_pattern(formula)
    if not pattern_dict:
        await update.message.reply_text(get_text(context, 'invalid_formula'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_WORD_FORMULA

    context.user_data['word_formula'] = formula
    await update.message.reply_text(get_text(context, 'ask_count_words'), reply_markup=get_stop_and_back_keyboard(context))
    return ASK_WORD_COUNT

async def handle_word_count_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        count = int(update.message.text.strip())
        if not (1 <= count <= 500):
            await update.message.reply_text(get_text(context, 'invalid_word_count'), reply_markup=get_stop_and_back_keyboard(context))
            return ASK_WORD_COUNT

        context.user_data['word_count'] = count

        await update.message.reply_text(get_text(context, 'generating_words'))

        length = context.user_data.get('word_length')
        formula = context.user_data.get('word_formula')
        words = generate_words(length=length, formula=formula, count=count, language=context.user_data.get('language', 'en'))

        if words:
            context.user_data['last_generated_words'] = words
            results_text = get_text(context, 'results_header').format(count=len(words))
            results_text += '\n'.join(f"â€¢ {word}" for word in words[:20])
            if len(words) > 20:
                results_text += f"\n\n... {len(words) - 20} " + get_text(context, 'show_more')

            await update.message.reply_text(
                results_text,
                reply_markup=get_result_screen_keyboard(context, for_words=True)
            )
            # Clear temporary word gen data
            context.user_data.pop('word_length', None)
            context.user_data.pop('word_formula', None)
            context.user_data.pop('word_count', None)
            return SHOW_WORD_RESULTS
        else:
            await update.message.reply_text(
                get_text(context, 'no_words_found'),
                reply_markup=get_word_gen_menu_keyboard(context)
            )
            # Clear temporary word gen data
            context.user_data.pop('word_length', None)
            context.user_data.pop('word_formula', None)
            context.user_data.pop('word_count', None)
            return ASK_WORD_LENGTH

    except ValueError:
        await update.message.reply_text(get_text(context, 'invalid_word_count'), reply_markup=get_stop_and_back_keyboard(context))
        return ASK_WORD_COUNT


async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data['stop_requested'] = True
    if 'processing_task' in context.user_data and not context.user_data['processing_task'].done():
        context.user_data['processing_task'].cancel()
        logger.info("Attempted to cancel processing task via /cancel command.")

    await update.message.reply_text(get_text(context, 'operation_cancelled'), reply_markup=get_main_menu_keyboard(context))
    return ConversationHandler.END


async def send_names_as_file(context: ContextTypes.DEFAULT_TYPE, chat_id: int, names_list: list[str], filename: str):
    if not names_list:
        await context.bot.send_message(chat_id=chat_id, text=get_text(context, 'no_names_to_save', filename=filename))
        return

    file_content = "\n".join(names_list)
    file_stream = io.BytesIO(file_content.encode('utf-8'))
    file_stream.name = filename

    try:
        if filename == "generated_words.txt":
            caption_key = 'word_file_created'
        else:
            caption_key = 'file_created'
        await context.bot.send_document(chat_id=chat_id, document=InputFile(file_stream), caption=get_text(context, caption_key))
        logger.info(f"Sent {filename} to chat {chat_id}")
    except Exception as e:
        logger.error(f"Failed to send document {filename} to chat {chat_id}: {e}")
        await context.bot.send_message(chat_id=chat_id, text=get_text(context, 'failed_to_send_file', error=str(e)))


if __name__ == '__main__':
    app = ApplicationBuilder().token(TOKEN).build()

    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("start", start)],
        states={
            INITIAL_MENU: [CallbackQueryHandler(handle_button_callbacks)],

            # States for Username Generation
            ASK_USERNAME_COUNT: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_username_count_input),
                CallbackQueryHandler(handle_button_callbacks)
            ],
            ASK_PATTERN: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_pattern_input),
                CallbackQueryHandler(handle_button_callbacks)
            ],
            ASK_DELAY: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_delay_input),
                CallbackQueryHandler(handle_button_callbacks)
            ],
            BULK_LIST: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, bulk_list_input),
                CallbackQueryHandler(handle_button_callbacks)
            ],
            HOW_TO_INFO: [
                CallbackQueryHandler(handle_button_callbacks)
            ],
            SET_LANGUAGE: [
                CallbackQueryHandler(handle_button_callbacks)
            ],

            # States for Word Generation (New)
            ASK_WORD_LENGTH: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_word_length_input),
                CallbackQueryHandler(handle_button_callbacks)
            ],
            ASK_WORD_FORMULA: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_word_formula_input),
                CallbackQueryHandler(handle_button_callbacks)
            ],
            ASK_WORD_COUNT: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_word_count_input),
                CallbackQueryHandler(handle_button_callbacks)
            ],
            SHOW_WORD_RESULTS: [
                CallbackQueryHandler(handle_button_callbacks)
            ]
        },
        fallbacks=[
            CommandHandler("cancel", cancel),
            CallbackQueryHandler(stop_processing_callback, pattern="^stop_processing$"),
            CallbackQueryHandler(handle_button_callbacks)
        ],
        per_message=False
    )

    app.add_handler(conv_handler)

    PORT = int(os.getenv("PORT", "8080"))
    WEBHOOK_URL = os.getenv("WEBHOOK_URL")

    WEBHOOK_SECRET_PATH = os.getenv("WEBHOOK_SECRET_PATH", f"webhook_{os.urandom(16).hex()}")
    logger.info(f"DEBUG: WEBHOOK_SECRET_PATH being used: {WEBHOOK_SECRET_PATH}")

    if WEBHOOK_URL:
        logger.info(f"Starting Webhook at {WEBHOOK_URL}/{WEBHOOK_SECRET_PATH} on port {PORT}")
        app.run_webhook(
            listen="0.0.0.0",
            port=PORT,
            url_path=WEBHOOK_SECRET_PATH,
            webhook_url=f"{WEBHOOK_URL}/{WEBHOOK_SECRET_PATH}"
        )
    else:
        logger.warning("No WEBHOOK_URL set. Running in polling mode. This is not recommended for production on Railway.")
        app.run_polling()

